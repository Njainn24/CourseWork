{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will find code that demonstrates how to run and interpret a logistic regression model. As before, please refer to the slides to get a full understanding of the motivations and derivations behind logistic regression and importantly its relation with the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in Titanic Data\n",
    "titanic = pd.read_csv(\"../../datasets/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Categorical Data (One-Hot-Encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical data, or data that have strings that denote something other than a numeric quantity, are extremely common in datasets. The catch is that, at least in Python, the vast majority of models do not know how to deal with categorical data - they prefer numeric data types only. At least in linear and logistic regression this makes intuitive sense because it doesn't make sense to invert a matrix of strings. What we do instead is do something called \"One-Hot-Encoding\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived                                               Name  \\\n",
       "0            1         0                            Braund, Mr. Owen Harris   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3         1                             Heikkinen, Miss. Laina   \n",
       "3            4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5         0                           Allen, Mr. William Henry   \n",
       "\n",
       "    Age  SibSp  Parch            Ticket     Fare Cabin  Sex_male  Pclass_2  \\\n",
       "0  22.0      1      0         A/5 21171   7.2500   NaN       1.0       0.0   \n",
       "1  38.0      1      0          PC 17599  71.2833   C85       0.0       0.0   \n",
       "2  26.0      0      0  STON/O2. 3101282   7.9250   NaN       0.0       0.0   \n",
       "3  35.0      1      0            113803  53.1000  C123       0.0       0.0   \n",
       "4  35.0      0      0            373450   8.0500   NaN       1.0       0.0   \n",
       "\n",
       "   Pclass_3  Embarked_Q  Embarked_S  \n",
       "0       1.0         0.0         1.0  \n",
       "1       0.0         0.0         0.0  \n",
       "2       1.0         0.0         1.0  \n",
       "3       0.0         0.0         1.0  \n",
       "4       1.0         0.0         1.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_only = pd.get_dummies(titanic,columns=['Sex','Pclass','Embarked'],drop_first=True)\n",
    "titanic_only.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you notice closely, there are now more than one column that represents a categorical variable! Sex is split into a male only column (1 if the corresponding Sex element was male) and a female only column, which is NOT shown because we chose to drop it from drop_first. Drop_first drops a single column from the new columns we've generated because this again has to do with multicollinearity. If I know that someone is male, then I know for sure someone is not female. As a result, just holding the male column is enough information for our model to handle, and we won't need to worry about multicollinearity issues!\n",
    "\n",
    "This process of converting a categorical column into multiple columns containing 0's and 1's is called one-hot-encoding and this technique is by far the most common way of feeding in categorical data into a model. Another way of describing this process is getting \"dummy variables\" (hence pd.get_dummies) which just refer to the variables with 1's and 0's. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop columns we don't care about (yet) or have missing values (Models don't like missing values)\n",
    "titanic_only.drop(['PassengerId','Name','Ticket','Age','Cabin'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train Test Splitting\n",
    "local_train, local_test = train_test_split(titanic_only,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 9)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 9)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_train_y = local_train[\"Survived\"]\n",
    "local_train_x = local_train.drop([\"Survived\"],axis=1)\n",
    "local_test_y = local_test[\"Survived\"]\n",
    "local_test_x = local_test.drop(\"Survived\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497509\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "#The Model\n",
    "clf = sm.Logit(local_train_y,local_train_x)\n",
    "result = clf.fit()\n",
    "preds = result.predict(local_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044692737430168"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of Logistic Model\n",
    "np.mean((preds > 0.5) == local_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Survived</td>     <th>  No. Observations:  </th>  <td>   712</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   704</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 28 Sep 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.2556</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>01:38:38</td>     <th>  Log-Likelihood:    </th> <td> -354.23</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -475.84</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>7.628e-49</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SibSp</th>      <td>   -0.2733</td> <td>    0.103</td> <td>   -2.662</td> <td> 0.008</td> <td>   -0.475    -0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Parch</th>      <td>    0.0138</td> <td>    0.133</td> <td>    0.104</td> <td> 0.917</td> <td>   -0.246     0.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fare</th>       <td>    0.0156</td> <td>    0.003</td> <td>    5.428</td> <td> 0.000</td> <td>    0.010     0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sex_male</th>   <td>   -2.1264</td> <td>    0.192</td> <td>  -11.061</td> <td> 0.000</td> <td>   -2.503    -1.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass_2</th>   <td>    0.5004</td> <td>    0.272</td> <td>    1.840</td> <td> 0.066</td> <td>   -0.033     1.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass_3</th>   <td>   -0.2624</td> <td>    0.248</td> <td>   -1.060</td> <td> 0.289</td> <td>   -0.748     0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_Q</th> <td>    0.6878</td> <td>    0.372</td> <td>    1.848</td> <td> 0.065</td> <td>   -0.042     1.417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_S</th> <td>    0.4359</td> <td>    0.239</td> <td>    1.820</td> <td> 0.069</td> <td>   -0.034     0.905</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               Survived   No. Observations:                  712\n",
       "Model:                          Logit   Df Residuals:                      704\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Wed, 28 Sep 2016   Pseudo R-squ.:                  0.2556\n",
       "Time:                        01:38:38   Log-Likelihood:                -354.23\n",
       "converged:                       True   LL-Null:                       -475.84\n",
       "                                        LLR p-value:                 7.628e-49\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "SibSp         -0.2733      0.103     -2.662      0.008        -0.475    -0.072\n",
       "Parch          0.0138      0.133      0.104      0.917        -0.246     0.274\n",
       "Fare           0.0156      0.003      5.428      0.000         0.010     0.021\n",
       "Sex_male      -2.1264      0.192    -11.061      0.000        -2.503    -1.750\n",
       "Pclass_2       0.5004      0.272      1.840      0.066        -0.033     1.033\n",
       "Pclass_3      -0.2624      0.248     -1.060      0.289        -0.748     0.223\n",
       "Embarked_Q     0.6878      0.372      1.848      0.065        -0.042     1.417\n",
       "Embarked_S     0.4359      0.239      1.820      0.069        -0.034     0.905\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's put some of the Data Cleaning and Feature Engineering from before to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in Titanic Data\n",
    "titanic = pd.read_csv(\"../../datasets/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_engineered = titanic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imputing Age\n",
    "titanic_engineered['title'] = 'other'\n",
    "titanic_engineered.loc[['Master.' in n for n in titanic_engineered['Name']],'title'] = 'Master'\n",
    "titanic_engineered.loc[['Miss.' in n for n in titanic_engineered['Name']],'title'] = 'Miss'\n",
    "titanic_engineered.loc[['Mr.' in n for n in titanic_engineered['Name']],'title'] = 'Mr'\n",
    "titanic_engineered.loc[['Mrs.' in n for n in titanic_engineered['Name']],'title'] = 'Mrs'\n",
    "\n",
    "#Transform performs operation per group and returns values to their original index\n",
    "titanic_engineered['age_filled'] = titanic_engineered[['title','Age']].groupby('title').transform(lambda x: x.fillna(x.mean())) \n",
    "\n",
    "titanic_engineered.drop(['Age'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cabin Side Feature\n",
    "titanic_engineered['cabin_side'] = 'Unknown'\n",
    "titanic_engineered.loc[titanic_engineered['Cabin'].str[-1].isin([\"1\", \"3\", \"5\", \"7\", \"9\"]),'cabin_side'] = 'starboard'\n",
    "titanic_engineered.loc[titanic_engineered['Cabin'].str[-1].isin([\"2\", \"4\", \"6\", \"8\", \"0\"]),'cabin_side'] = 'port'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Deck Feature (including some cleaning)\n",
    "titanic_engineered['deck'] = 'Unknown'\n",
    "titanic_engineered.loc[titanic_engineered['Cabin'].notnull(),'deck'] = titanic_engineered['Cabin'].str[0]\n",
    "titanic_engineered.loc[titanic_engineered['deck'] == 'T','deck'] = \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Deck Feature (including some cleaning)\n",
    "titanic_engineered['deck'] = 'Unknown'\n",
    "titanic_engineered.loc[titanic_engineered['Cabin'].notnull(),'deck'] = titanic_engineered['Cabin'].str[0]\n",
    "titanic_engineered.loc[titanic_engineered['deck'] == 'T','deck'] = \"Unknown\"\n",
    "\n",
    "pattern = \"[A-Z]\\s[A-Z]\" #Any capital letter between A-Z followed by a whitespace followed by any letter between A-Z\n",
    "mask = titanic_engineered['Cabin'].str.contains(pattern,na=False)\n",
    "titanic_engineered.loc[mask,'deck'] = titanic_engineered.loc[mask,'Cabin'].str[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Number cabins per person\n",
    "titanic_engineered['num_in_group'] = titanic_engineered['Cabin'].str.split().apply(lambda x: len(x) if type(x)!=float else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removing columns we don't want (that don't make sense to include anymore)\n",
    "#Notice we are NOT dropping the Age column anymore because we've filled in the missing values!\n",
    "titanic_engineered.drop(['PassengerId','Name','Ticket','Cabin','title'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting Dummy Variables\n",
    "titanic_engineered = pd.get_dummies(titanic_engineered,columns=['Sex','Pclass','Embarked','cabin_side','deck'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train Test Splitting\n",
    "local_train, local_test = train_test_split(titanic_engineered,test_size=0.2,random_state=123)\n",
    "\n",
    "local_train_y = local_train[\"Survived\"]\n",
    "local_train_x = local_train.drop([\"Survived\"],axis=1)\n",
    "local_test_y = local_test[\"Survived\"]\n",
    "local_test_x = local_test.drop(\"Survived\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.434784\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "#The Model\n",
    "clf = sm.Logit(local_train_y,local_train_x)\n",
    "result = clf.fit()\n",
    "preds = result.predict(local_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82681564245810057"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of Logistic Model\n",
    "np.mean((preds > 0.5) == local_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Survived</td>     <th>  No. Observations:  </th>  <td>   712</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   693</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    18</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 28 Sep 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.3494</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>01:38:42</td>     <th>  Log-Likelihood:    </th> <td> -309.57</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -475.84</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>9.315e-60</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SibSp</th>                <td>   -0.3718</td> <td>    0.123</td> <td>   -3.016</td> <td> 0.003</td> <td>   -0.613    -0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Parch</th>                <td>   -0.0317</td> <td>    0.141</td> <td>   -0.224</td> <td> 0.822</td> <td>   -0.309     0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fare</th>                 <td>    0.0017</td> <td>    0.003</td> <td>    0.580</td> <td> 0.562</td> <td>   -0.004     0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_filled</th>           <td>   -0.0450</td> <td>    0.009</td> <td>   -4.865</td> <td> 0.000</td> <td>   -0.063    -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_in_group</th>         <td>   -0.2892</td> <td>    0.472</td> <td>   -0.612</td> <td> 0.540</td> <td>   -1.215     0.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sex_male</th>             <td>   -2.6553</td> <td>    0.230</td> <td>  -11.525</td> <td> 0.000</td> <td>   -3.107    -2.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass_2</th>             <td>   -0.4183</td> <td>    0.482</td> <td>   -0.867</td> <td> 0.386</td> <td>   -1.364     0.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pclass_3</th>             <td>   -1.4352</td> <td>    0.481</td> <td>   -2.986</td> <td> 0.003</td> <td>   -2.377    -0.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_Q</th>           <td>   -0.2604</td> <td>    0.430</td> <td>   -0.606</td> <td> 0.545</td> <td>   -1.103     0.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Embarked_S</th>           <td>   -0.4708</td> <td>    0.283</td> <td>   -1.662</td> <td> 0.097</td> <td>   -1.026     0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cabin_side_port</th>      <td>    4.0991</td> <td>    0.868</td> <td>    4.720</td> <td> 0.000</td> <td>    2.397     5.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cabin_side_starboard</th> <td>    4.6999</td> <td>    0.944</td> <td>    4.979</td> <td> 0.000</td> <td>    2.850     6.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deck_B</th>               <td>    0.4692</td> <td>    0.864</td> <td>    0.543</td> <td> 0.587</td> <td>   -1.224     2.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deck_C</th>               <td>    0.3191</td> <td>    0.743</td> <td>    0.429</td> <td> 0.668</td> <td>   -1.137     1.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deck_D</th>               <td>    1.4357</td> <td>    0.821</td> <td>    1.749</td> <td> 0.080</td> <td>   -0.173     3.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deck_E</th>               <td>    1.1737</td> <td>    0.813</td> <td>    1.443</td> <td> 0.149</td> <td>   -0.420     2.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deck_F</th>               <td>    1.3834</td> <td>    1.233</td> <td>    1.122</td> <td> 0.262</td> <td>   -1.033     3.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deck_G</th>               <td>   -1.0403</td> <td>    1.318</td> <td>   -0.790</td> <td> 0.430</td> <td>   -3.623     1.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deck_Unknown</th>         <td>    3.9204</td> <td>    0.730</td> <td>    5.369</td> <td> 0.000</td> <td>    2.489     5.351</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               Survived   No. Observations:                  712\n",
       "Model:                          Logit   Df Residuals:                      693\n",
       "Method:                           MLE   Df Model:                           18\n",
       "Date:                Wed, 28 Sep 2016   Pseudo R-squ.:                  0.3494\n",
       "Time:                        01:38:42   Log-Likelihood:                -309.57\n",
       "converged:                       True   LL-Null:                       -475.84\n",
       "                                        LLR p-value:                 9.315e-60\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------------\n",
       "SibSp                   -0.3718      0.123     -3.016      0.003        -0.613    -0.130\n",
       "Parch                   -0.0317      0.141     -0.224      0.822        -0.309     0.245\n",
       "Fare                     0.0017      0.003      0.580      0.562        -0.004     0.008\n",
       "age_filled              -0.0450      0.009     -4.865      0.000        -0.063    -0.027\n",
       "num_in_group            -0.2892      0.472     -0.612      0.540        -1.215     0.637\n",
       "Sex_male                -2.6553      0.230    -11.525      0.000        -3.107    -2.204\n",
       "Pclass_2                -0.4183      0.482     -0.867      0.386        -1.364     0.527\n",
       "Pclass_3                -1.4352      0.481     -2.986      0.003        -2.377    -0.493\n",
       "Embarked_Q              -0.2604      0.430     -0.606      0.545        -1.103     0.582\n",
       "Embarked_S              -0.4708      0.283     -1.662      0.097        -1.026     0.084\n",
       "cabin_side_port          4.0991      0.868      4.720      0.000         2.397     5.801\n",
       "cabin_side_starboard     4.6999      0.944      4.979      0.000         2.850     6.550\n",
       "deck_B                   0.4692      0.864      0.543      0.587        -1.224     2.163\n",
       "deck_C                   0.3191      0.743      0.429      0.668        -1.137     1.775\n",
       "deck_D                   1.4357      0.821      1.749      0.080        -0.173     3.045\n",
       "deck_E                   1.1737      0.813      1.443      0.149        -0.420     2.767\n",
       "deck_F                   1.3834      1.233      1.122      0.262        -1.033     3.800\n",
       "deck_G                  -1.0403      1.318     -0.790      0.430        -3.623     1.542\n",
       "deck_Unknown             3.9204      0.730      5.369      0.000         2.489     5.351\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation (Basic Data Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splits data into our train and test indices for each fold\n",
    "kf = KFold(titanic_only.shape[0], n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saves our accuracy scores for each fold\n",
    "outcomes = []\n",
    "\n",
    "#Keeps track of which fold we are currently in\n",
    "fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.486011\n",
      "         Iterations 6\n",
      "Fold 1 accuracy: 0.7555555555555555\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.491157\n",
      "         Iterations 6\n",
      "Fold 2 accuracy: 0.8314606741573034\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482838\n",
      "         Iterations 6\n",
      "Fold 3 accuracy: 0.7640449438202247\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.490833\n",
      "         Iterations 6\n",
      "Fold 4 accuracy: 0.8426966292134831\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482505\n",
      "         Iterations 6\n",
      "Fold 5 accuracy: 0.7528089887640449\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.485408\n",
      "         Iterations 6\n",
      "Fold 6 accuracy: 0.7752808988764045\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482177\n",
      "         Iterations 6\n",
      "Fold 7 accuracy: 0.7640449438202247\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.483291\n",
      "         Iterations 6\n",
      "Fold 8 accuracy: 0.7528089887640449\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497325\n",
      "         Iterations 6\n",
      "Fold 9 accuracy: 0.8651685393258427\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.486352\n",
      "         Iterations 6\n",
      "Fold 10 accuracy: 0.7640449438202247\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf:\n",
    "    fold += 1\n",
    "    local_train_xy, local_test_xy = titanic_only.iloc[train_index], titanic_only.iloc[test_index]\n",
    "    local_train_y = local_train_xy['Survived']\n",
    "    local_train_x = local_train_xy.drop(['Survived'],axis=1)\n",
    "    local_test_y = local_test_xy['Survived']\n",
    "    local_test_x = local_test_xy.drop(['Survived'],axis=1)\n",
    "\n",
    "    clf = sm.Logit(local_train_y,local_train_x)\n",
    "    result = clf.fit()\n",
    "    preds = result.predict(local_test_x)\n",
    "    accuracy = np.mean((preds > 0.5) == local_test_y)\n",
    "\n",
    "    outcomes.append(accuracy)\n",
    "    print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78679151061173536"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Cross Validated (average) score\n",
    "mean_outcome = np.mean(outcomes)\n",
    "mean_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation (Feature Engineered Data Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saves our accuracy scores for each fold\n",
    "outcomes = []\n",
    "\n",
    "#Keeps track of which fold we are currently in\n",
    "fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.426672\n",
      "         Iterations 6\n",
      "Fold 1 accuracy: 0.8111111111111111\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.424065\n",
      "         Iterations 7\n",
      "Fold 2 accuracy: 0.797752808988764\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.422449\n",
      "         Iterations 6\n",
      "Fold 3 accuracy: 0.8089887640449438\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.422501\n",
      "         Iterations 7\n",
      "Fold 4 accuracy: 0.8202247191011236\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.423288\n",
      "         Iterations 7\n",
      "Fold 5 accuracy: 0.7752808988764045\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.423060\n",
      "         Iterations 7\n",
      "Fold 6 accuracy: 0.7640449438202247\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.424933\n",
      "         Iterations 6\n",
      "Fold 7 accuracy: 0.797752808988764\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.421910\n",
      "         Iterations 6\n",
      "Fold 8 accuracy: 0.8089887640449438\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.436454\n",
      "         Iterations 6\n",
      "Fold 9 accuracy: 0.8764044943820225\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.429371\n",
      "         Iterations 6\n",
      "Fold 10 accuracy: 0.8314606741573034\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf:\n",
    "    fold += 1\n",
    "    local_train_xy, local_test_xy = titanic_engineered.iloc[train_index], titanic_engineered.iloc[test_index]\n",
    "    local_train_y = local_train_xy['Survived']\n",
    "    local_train_x = local_train_xy.drop(['Survived'],axis=1)\n",
    "    local_test_y = local_test_xy['Survived']\n",
    "    local_test_x = local_test_xy.drop(['Survived'],axis=1)\n",
    "\n",
    "    clf = sm.Logit(local_train_y,local_train_x)\n",
    "    result = clf.fit()\n",
    "    preds = result.predict(local_test_x)\n",
    "    accuracy = np.mean((preds > 0.5) == local_test_y)\n",
    "\n",
    "    outcomes.append(accuracy)\n",
    "    print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8092009987515606"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_outcome = np.mean(outcomes)\n",
    "mean_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
